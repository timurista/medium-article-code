{
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "# Enhancing Security: Dataset Generation for Next-Gen Intrusion Detection Systems",
                "\nThis notebook demonstrates key concepts and code examples for generating and working with datasets for modern intrusion detection systems (IDS). We'll explore dataset quality, handling encrypted traffic, and best practices for IDS development."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Required Libraries",
                "\nFirst, let's import the necessary Python libraries for our analysis:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.ensemble import IsolationForest\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "# Set plotting style\n",
                "plt.style.use('seaborn')\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading and Exploring Sample Network Traffic Data",
                "\nWe'll create a sample dataset that mimics network traffic patterns:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate sample network traffic data\n",
                "np.random.seed(42)\n",
                "n_samples = 1000\n",
                "\n",
                "data = {\n",
                    "'packet_size': np.random.normal(500, 150, n_samples),\n",
                    "'duration': np.random.exponential(2, n_samples),\n",
                    "'protocol': np.random.choice(['TCP', 'UDP', 'ICMP'], n_samples),\n",
                    "'is_encrypted': np.random.choice([0, 1], n_samples, p=[0.3, 0.7])\n",
                "}\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "\n",
                "# Add some anomalous traffic\n",
                "anomaly_idx = np.random.choice(n_samples, size=int(0.1 * n_samples), replace=False)\n",
                "df.loc[anomaly_idx, 'packet_size'] *= 3  # Abnormally large packets\n",
                "\n",
                "print('Dataset shape:', df.shape)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analyzing Traffic Patterns",
                "\nLet's visualize the distribution of packet sizes and compare encrypted vs non-encrypted traffic:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Packet size distribution\n",
                "sns.histplot(data=df, x='packet_size', hue='is_encrypted', bins=30, ax=ax1)\n",
                "ax1.set_title('Packet Size Distribution by Encryption Status')\n",
                "\n",
                "# Protocol distribution\n",
                "sns.countplot(data=df, x='protocol', hue='is_encrypted', ax=ax2)\n",
                "ax2.set_title('Protocol Distribution by Encryption Status')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementing Basic Anomaly Detection",
                "\nNow let's implement a simple anomaly detection system using Isolation Forest:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features for anomaly detection\n",
                "X = df[['packet_size', 'duration']].copy()\n",
                "\n",
                "# Initialize and fit the Isolation Forest model\n",
                "model = IsolationForest(contamination=0.1, random_state=42)\n",
                "predictions = model.fit_predict(X)\n",
                "\n",
                "# Convert predictions to boolean (True for anomalies)\n",
                "df['is_anomaly'] = predictions == -1\n",
                "\n",
                "# Visualize results\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=df, x='packet_size', y='duration', \n",
                               "hue='is_anomaly', style='is_encrypted')\n",
                "plt.title('Anomaly Detection Results')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best Practices and Error Handling",
                "\nHere's an example of implementing error handling and best practices for dataset processing:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_network_data(df, required_columns=['packet_size', 'duration']):\n",
                    "\"\"\"Process network traffic data with error handling.\n",
                    "\n",
                    "Args:\n",
                        "df (pd.DataFrame): Input network traffic data\n",
                        "required_columns (list): Required columns for processing\n",
                    "\n",
                    "Returns:\n",
                        "pd.DataFrame: Processed data\n",
                    "\"\"\"\n",
                    "try:\n",
                        "# Validate input\n",
                        "if not isinstance(df, pd.DataFrame):\n",
                            "raise TypeError(\"Input must be a pandas DataFrame\")\n",
                            "\n",
                        "# Check required columns\n",
                        "missing_cols = set(required_columns) - set(df.columns)\n",
                        "if missing_cols:\n",
                            "raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
                            "\n",
                        "# Remove invalid values\n",
                        "df_clean = df.copy()\n",
                        "df_clean = df_clean.dropna(subset=required_columns)\n",
                        "df_clean = df_clean[df_clean['packet_size'] > 0]\n",
                        "\n",
                        "return df_clean\n",
                        "\n",
                    "except Exception as e:\n",
                        "print(f\"Error processing data: {str(e)}\")\n",
                        "return None\n",
                "\n",
                "# Test the function\n",
                "processed_df = process_network_data(df)\n",
                "print(\"Processed data shape:\", processed_df.shape if processed_df is not None else None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion",
                "\nIn this notebook, we've demonstrated:\n",
                "1. Loading and processing network traffic data\n",
                "2. Visualizing traffic patterns and encryption status\n",
                "3. Implementing basic anomaly detection\n",
                "4. Best practices for error handling and data validation\n",
                "\nThese concepts form the foundation for building robust intrusion detection systems that can handle modern challenges like encrypted traffic."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python", 
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}