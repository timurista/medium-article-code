{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Implementing MemGPT for Enhanced LLM Memory Management\n",
                "\nThis notebook demonstrates practical implementations of MemGPT concepts for improving memory management in Large Language Models (LLMs). We'll explore core concepts, implementation techniques, and real-world applications."
            ]
        },
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "## Setup and Dependencies\n",
                "\nFirst, let's install and import the required libraries:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Install required packages\n",
                "!pip install sentence-transformers torch numpy pandas matplotlib\n",
                "\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Memory Management Implementation\n",
                "\nLet's implement basic short-term and long-term memory systems:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class MemoryManager:\n",
                "    def __init__(self, stm_capacity=5):\n",
                "        self.stm = []  # Short-term memory\n",
                "        self.ltm = {}  # Long-term memory\n",
                "        self.stm_capacity = stm_capacity\n",
                "        \n",
                "    def add_to_stm(self, input_text):\n",
                "        \"\"\"Add item to short-term memory with capacity limit\"\"\"\n",
                "        if len(self.stm) >= self.stm_capacity:\n",
                "            self.stm.pop(0)\n",
                "        self.stm.append(input_text)\n",
                "        \n",
                "    def add_to_ltm(self, key, value):\n",
                "        \"\"\"Store information in long-term memory\"\"\"\n",
                "        self.ltm[key] = value\n",
                "        \n",
                "    def get_stm_context(self):\n",
                "        \"\"\"Return current short-term memory context\"\"\"\n",
                "        return ' '.join(self.stm)\n",
                "    \n",
                "    def recall_from_ltm(self, key):\n",
                "        \"\"\"Retrieve information from long-term memory\"\"\"\n",
                "        return self.ltm.get(key, 'Information not found')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Embedding Generation\n",
                "\nImplement semantic embedding generation for better context understanding:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class EmbeddingManager:\n",
                "    def __init__(self):\n",
                "        self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
                "        \n",
                "    def generate_embeddings(self, texts):\n",
                "        \"\"\"Generate embeddings for input texts\"\"\"\n",
                "        if isinstance(texts, str):\n",
                "            texts = [texts]\n",
                "        return self.model.encode(texts)\n",
                "    \n",
                "    def calculate_similarity(self, text1, text2):\n",
                "        \"\"\"Calculate cosine similarity between two texts\"\"\"\n",
                "        emb1 = self.generate_embeddings(text1)\n",
                "        emb2 = self.generate_embeddings(text2)\n",
                "        return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Demonstration and Testing\n",
                "\nLet's test our implementation with some example conversations:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Initialize managers\n",
                "memory_mgr = MemoryManager()\n",
                "embedding_mgr = EmbeddingManager()\n",
                "\n",
                "# Simulate conversation\n",
                "conversation = [\n",
                "    \"Hello, my name is Alice.\",\n",
                "    \"I like playing tennis.\",\n",
                "    \"My favorite color is blue.\",\n",
                "    \"I live in New York.\"\n",
                "]\n",
                "\n",
                "# Process conversation\n",
                "for utterance in conversation:\n",
                "    memory_mgr.add_to_stm(utterance)\n",
                "    \n",
                "# Store some information in LTM\n",
                "memory_mgr.add_to_ltm('user_name', 'Alice')\n",
                "memory_mgr.add_to_ltm('favorite_color', 'blue')\n",
                "\n",
                "# Print current context\n",
                "print(\"Current conversation context:\")\n",
                "print(memory_mgr.get_stm_context())\n",
                "print(\"\\nRecalled information:\")\n",
                "print(f\"User name: {memory_mgr.recall_from_ltm('user_name')}\")\n",
                "print(f\"Favorite color: {memory_mgr.recall_from_ltm('favorite_color')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizing Memory Management\n",
                "\nLet's create a visualization of memory usage and embeddings:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Generate embeddings for visualization\n",
                "embeddings = embedding_mgr.generate_embeddings(conversation)\n",
                "\n",
                "# Create visualization\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(range(len(memory_mgr.stm)), [1]*len(memory_mgr.stm), 'bo-')\n",
                "plt.title('Short-term Memory Usage')\n",
                "plt.xlabel('Time Steps')\n",
                "plt.ylabel('Memory Slots')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.imshow(embeddings @ embeddings.T)\n",
                "plt.title('Embedding Similarities')\n",
                "plt.colorbar()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}