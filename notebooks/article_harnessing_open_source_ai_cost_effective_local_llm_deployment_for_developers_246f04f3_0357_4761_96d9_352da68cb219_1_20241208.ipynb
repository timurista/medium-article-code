{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Harnessing Open-Source AI: Cost-effective Local LLM Deployment",
                "",
                "This notebook demonstrates how to set up and use local LLM deployments using OpenAI Swarm and Ollama frameworks. We'll cover setting up the environment, building AI agents, and exploring advanced functionalities."
            ]
        },
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "## Setup and Requirements",
                "",
                "First, let's install the required packages and set up our environment:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install openai-swarm\n",
                "!pip install opencv-python matplotlib\n",
                "\n",
                "# Import necessary libraries\n",
                "import openai_swarm\n",
                "import matplotlib.pyplot as plt\n",
                "import cv2\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {}, 
            "source": [
                "## Building Our First Agent",
                "",
                "Let's create a simple rephrasing agent using the Llama3.2:1b model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def rephraser_agent(input_text):\n",
                "    try:\n",
                "        # Create agent using Llama model\n",
                "        rephrased_response = openai_swarm.create_agent(\"llama3:1b\", input_text)\n",
                "        return rephrased_response\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        return None\n",
                "\n",
                "# Test the agent\n",
                "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
                "result = rephraser_agent(test_text)\n",
                "print(f\"Original: {test_text}\")\n",
                "print(f\"Rephrased: {result}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Advanced Usage: Multi-Function Agent",
                "",
                "Now let's create a more sophisticated agent that can handle multiple tasks:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MultiAgent:\n",
                "    def __init__(self):\n",
                "        self.model = \"llama3:1b\"\n",
                "    \n",
                "    def process_text(self, text, mode='rephrase'):\n",
                "        try:\n",
                "            if mode == 'rephrase':\n",
                "                return openai_swarm.create_agent(self.model, f\"rephrase: {text}\")\n",
                "            elif mode == 'summarize':\n",
                "                return openai_swarm.create_agent(self.model, f\"summarize: {text}\")\n",
                "            else:\n",
                "                raise ValueError(f\"Unknown mode: {mode}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error processing text: {e}\")\n",
                "            return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization Example",
                "",
                "Let's create a simple visualization to track agent performance:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_response_times(times, modes):\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.bar(modes, times)\n",
                "    plt.title('Response Times by Mode')\n",
                "    plt.xlabel('Processing Mode')\n",
                "    plt.ylabel('Time (seconds)')\n",
                "    plt.show()\n",
                "\n",
                "# Example usage\n",
                "sample_times = [0.5, 0.8]\n",
                "sample_modes = ['rephrase', 'summarize']\n",
                "plot_response_times(sample_times, sample_modes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best Practices and Tips",
                "",
                "1. Always use try-except blocks for error handling\n",
                "2. Monitor resource usage when running local models\n",
                "3. Implement proper logging and monitoring\n",
                "4. Consider batch processing for large datasets\n",
                "5. Regularly update model weights and dependencies"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion",
                "",
                "This notebook demonstrated the basics of setting up and using local LLM deployments with OpenAI Swarm. We covered:\n",
                "- Basic agent creation\n",
                "- Multi-function agents\n",
                "- Error handling\n",
                "- Performance visualization\n",
                "",
                "For more advanced usage, refer to the official documentation and community resources."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python", 
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}