{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Scaling Local AI Solutions: A Guide for Small Businesses and Independent Developers",
                "",
                "This notebook demonstrates practical implementations of local AI solutions for small businesses and independent developers. We'll cover setup, integration, best practices, and real-world examples."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Required Package Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import transformers\nimport torch\nimport psutil\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\nfrom sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "## 1. Setting Up Local AI Environment",
                "",
                "Let's start by setting up a basic local AI environment using the Hugging Face Transformers library."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize a simple text generation pipeline\ntry:\n    text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n    print(\"Model loaded successfully!\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. System Resource Monitoring",
                "",
                "Let's create a function to monitor system resources when running AI models locally."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def monitor_resources():\n    cpu_percent = psutil.cpu_percent(interval=1)\n    memory = psutil.virtual_memory()\n    \n    # Create visualization\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    # CPU Usage Plot\n    ax1.bar(['CPU Usage'], [cpu_percent])\n    ax1.set_ylim(0, 100)\n    ax1.set_title('CPU Usage (%)')\n    \n    # Memory Usage Plot\n    memory_data = [memory.percent, 100-memory.percent]\n    ax2.pie(memory_data, labels=['Used', 'Free'], autopct='%1.1f%%')\n    ax2.set_title('Memory Usage')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return cpu_percent, memory.percent\n\n# Call the function\nmonitor_resources()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Example Text Classification Task",
                "",
                "Let's implement a simple sentiment analysis task using a local model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample data\nsample_texts = [\n    \"Great product, highly recommend!\",\n    \"This service was terrible\",\n    \"Average experience, nothing special\"\n]\n\n# Initialize sentiment analyzer\ntry:\n    sentiment_analyzer = pipeline(\"sentiment-analysis\")\n    results = sentiment_analyzer(sample_texts)\n    \n    # Create DataFrame for visualization\n    df = pd.DataFrame({\n        'Text': sample_texts,\n        'Sentiment': [r['label'] for r in results],\n        'Score': [r['score'] for r in results]\n    })\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    sns.barplot(data=df, x='Text', y='Score', hue='Sentiment')\n    plt.xticks(rotation=45)\n    plt.title('Sentiment Analysis Results')\n    plt.tight_layout()\n    plt.show()\n    \nexcept Exception as e:\n    print(f\"Error in sentiment analysis: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best Practices and Tips",
                "",
                "1. Always monitor system resources when running local AI models",
                "2. Implement proper error handling",
                "3. Use smaller models initially and scale up as needed",
                "4. Cache results when possible to improve performance",
                "5. Regular model evaluation and updates are crucial"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion",
                "",
                "This notebook demonstrated basic concepts of implementing local AI solutions. Key takeaways:",
                "",
                "- Environment setup and resource monitoring",
                "- Basic model implementation",
                "- Performance visualization",
                "- Error handling and best practices",
                "",
                "For production use, consider scaling these examples based on your specific business needs."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python", 
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}