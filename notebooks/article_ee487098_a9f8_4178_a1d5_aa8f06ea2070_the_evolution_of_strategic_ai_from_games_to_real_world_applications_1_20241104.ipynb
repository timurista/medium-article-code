{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# The Evolution of Strategic AI: From Games to Real-World Applications",
                "",
                "This notebook explores the evolution of strategic AI, from its roots in game theory to modern real-world applications. We'll examine key concepts, implementation examples, and practical applications across different domains."
            ]
        },
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "## Setup and Required Libraries",
                "",
                "First, let's import the necessary libraries we'll use throughout this notebook:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 1: Historical Context - Basic Reinforcement Learning",
                "",
                "Let's implement a simple reinforcement learning agent to demonstrate the fundamental concepts that laid the groundwork for strategic AI:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class ReinforcementLearningAgent:\n    def __init__(self, actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n        self.q_table = np.zeros(actions)\n        self.alpha = alpha  # Learning rate\n        self.gamma = gamma  # Discount factor\n        self.epsilon = epsilon  # Exploration rate\n        \n    def choose_action(self):\n        # Epsilon-greedy strategy\n        if np.random.random() < self.epsilon:\n            return np.random.randint(len(self.q_table))\n        return np.argmax(self.q_table)\n    \n    def update_q_value(self, action, reward, next_best_value):\n        # Q-learning update formula\n        td_target = reward + self.gamma * next_best_value\n        self.q_table[action] += self.alpha * (td_target - self.q_table[action])\n        \n# Create agent and demonstrate basic learning\nagent = ReinforcementLearningAgent(actions=5)\n\n# Simulate some learning episodes\nfor _ in range(100):\n    action = agent.choose_action()\n    reward = np.random.normal(0, 1)  # Random reward for demonstration\n    next_best_value = np.max(agent.q_table)\n    agent.update_q_value(action, reward, next_best_value)\n\nprint('Final Q-values:', agent.q_table)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 2: Implementing Game Theory Concepts",
                "",
                "Let's implement a simple zero-sum game to demonstrate basic game theory principles:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class SimpleGame:\n    def __init__(self):\n        # Payoff matrix for a simple 2x2 game\n        self.payoff_matrix = np.array([\n            [[1, -1], [-1, 1]],\n            [[-1, 1], [1, -1]]\n        ])\n    \n    def get_nash_equilibrium(self):\n        # Find pure strategy Nash equilibrium\n        shape = self.payoff_matrix.shape[:2]\n        nash_equilibria = []\n        \n        for i in range(shape[0]):\n            for j in range(shape[1]):\n                # Check if this strategy pair is a Nash equilibrium\n                player1_payoff = self.payoff_matrix[i, j, 0]\n                player2_payoff = self.payoff_matrix[i, j, 1]\n                \n                is_nash = True\n                # Check if any player can improve by deviating\n                for i2 in range(shape[0]):\n                    if self.payoff_matrix[i2, j, 0] > player1_payoff:\n                        is_nash = False\n                for j2 in range(shape[1]):\n                    if self.payoff_matrix[i, j2, 1] > player2_payoff:\n                        is_nash = False\n                        \n                if is_nash:\n                    nash_equilibria.append((i, j))\n        \n        return nash_equilibria\n\n# Create and analyze game\ngame = SimpleGame()\nequilibria = game.get_nash_equilibrium()\nprint('Nash equilibria:', equilibria)"
            ]
        }
    ]
}