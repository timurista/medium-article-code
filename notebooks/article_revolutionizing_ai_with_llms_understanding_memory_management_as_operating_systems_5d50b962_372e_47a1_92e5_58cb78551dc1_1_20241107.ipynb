{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Revolutionizing AI with LLMs: Understanding Memory Management",
                "\nThis notebook demonstrates key concepts in LLM memory management, implementations of memory systems, and practical applications."
            ]
        },
        {
            "cell_type": "markdown", 
            "metadata": {},
            "source": [
                "## Setup and Requirements",
                "\nFirst, let's import required libraries and set up our environment:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Understanding Context Window Limitations",
                "\nLet's demonstrate the context window limitation issue with a practical example:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Initialize tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\n# Example long text that exceeds context window\nlong_text = ' '.join(['This is a very long text'] * 500)\n\n# Tokenize\ninput_ids = tokenizer.encode(long_text, return_tensors='pt')\n\n# Check token length\nprint(f'Input length: {input_ids.shape[1]} tokens')\nprint(f'Model max length: {model.config.n_positions} tokens')\n\n# Demonstrate truncation\nif input_ids.shape[1] > model.config.n_positions:\n    print('\\nText exceeds context window - truncating...')\n    input_ids = input_ids[:, :model.config.n_positions]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Implementing a Memory Management System",
                "\nLet's create a basic implementation of a tiered memory system similar to MemGPT:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class TieredMemorySystem:\n    def __init__(self):\n        self.core_memory = []  # Short-term, immediate access\n        self.conversation_memory = []  # Recent conversation history\n        self.archival_memory = {}  # Long-term storage\n        \n        # Memory limits\n        self.core_memory_limit = 5\n        self.conversation_memory_limit = 20\n        \n    def add_to_core_memory(self, item):\n        if len(self.core_memory) >= self.core_memory_limit:\n            # Move oldest item to conversation memory\n            self.conversation_memory.append(self.core_memory.pop(0))\n        self.core_memory.append(item)\n        \n    def add_to_conversation_memory(self, item):\n        if len(self.conversation_memory) >= self.conversation_memory_limit:\n            # Archive oldest conversation\n            timestamp = len(self.archival_memory)\n            self.archival_memory[timestamp] = self.conversation_memory.pop(0)\n        self.conversation_memory.append(item)\n        \n    def get_context(self):\n        return {\n            'core': self.core_memory,\n            'conversation': self.conversation_memory,\n            'archival_size': len(self.archival_memory)\n        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Testing the Memory System",
                "\nLet's demonstrate how the tiered memory system works with a simulated conversation:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Initialize memory system\nmemory_system = TieredMemorySystem()\n\n# Simulate conversation\nconversation = [\n    \"User asks about climate change\",\n    \"Bot provides overview of global warming\",\n    \"User asks about specific impacts\",\n    \"Bot discusses rising sea levels\",\n    \"User asks about solutions\",\n    \"Bot suggests renewable energy\"\n]\n\n# Process conversation\nfor message in conversation:\n    memory_system.add_to_core_memory(message)\n    \n# Print current state\nprint('Memory System State:')\nprint('\\nCore Memory:')\nprint('\\n'.join(memory_system.core_memory))\nprint('\\nConversation Memory:')\nprint('\\n'.join(memory_system.conversation_memory))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizing Memory Usage",
                "\nLet's create a visualization of memory usage across different tiers:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def plot_memory_usage(memory_system):\n    memory_stats = {\n        'Core Memory': len(memory_system.core_memory),\n        'Conversation Memory': len(memory_system.conversation_memory),\n        'Archival Memory': len(memory_system.archival_memory)\n    }\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(memory_stats.keys(), memory_stats.values())\n    plt.title('Memory Usage Across Tiers')\n    plt.ylabel('Number of Items')\n    plt.show()\n\nplot_memory_usage(memory_system)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    }
}